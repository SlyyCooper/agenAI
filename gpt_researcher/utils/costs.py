import tiktoken

# Per OpenAI Pricing Page: https://openai.com/api/pricing/
# These constants represent the current pricing for different OpenAI API operations
ENCODING_MODEL = "o200k_base"  # The encoding model used for tokenization
INPUT_COST_PER_TOKEN = 0.000005  # Cost per input token
OUTPUT_COST_PER_TOKEN = 0.000015  # Cost per output token
IMAGE_INFERENCE_COST = 0.003825  # Cost for image inference (not used in this file)
EMBEDDING_COST = 0.02 / 1000000  # Cost per token for embeddings, assumes new ada-3-small model

# Cost estimation is via OpenAI libraries and models. May vary for other models
def estimate_llm_cost(input_content: str, output_content: str) -> float:
    """
    Estimate the cost of using the LLM (Language Model) based on input and output content.
    
    Args:
    input_content (str): The input text to the LLM
    output_content (str): The output text generated by the LLM
    
    Returns:
    float: The estimated cost of the LLM operation
    """
    # Get the appropriate encoding for the model
    encoding = tiktoken.get_encoding(ENCODING_MODEL)
    
    # Encode the input and output content to get token counts
    input_tokens = encoding.encode(input_content)
    output_tokens = encoding.encode(output_content)
    
    # Calculate costs based on token counts and per-token prices
    input_costs = len(input_tokens) * INPUT_COST_PER_TOKEN
    output_costs = len(output_tokens) * OUTPUT_COST_PER_TOKEN
    
    # Return the total estimated cost
    return input_costs + output_costs


def estimate_embedding_cost(model, docs):
    """
    Estimate the cost of creating embeddings for a set of documents.
    
    Args:
    model (str): The name of the embedding model
    docs (list): A list of documents to be embedded
    
    Returns:
    float: The estimated cost of creating embeddings for all documents
    """
    # Get the appropriate encoding for the specified model
    encoding = tiktoken.encoding_for_model(model)
    
    # Calculate the total number of tokens across all documents
    total_tokens = sum(len(encoding.encode(str(doc))) for doc in docs)
    
    # Calculate and return the total cost based on the number of tokens
    return total_tokens * EMBEDDING_COST

